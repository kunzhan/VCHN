Parameter settings: Namespace(alpha_2=0.2, cuda=True, dataset='cora', dropout_1=0.5, dropout_2=0.6, epochs=2000, fastmode=True, hidden_1=16, hidden_2=16, k=11, lr=0.01, nb_heads_2=3, patience=100, percent=0.02, public=0, seed=42, t1=160, t2=260, weight_decay=0.0005)
*******************************************************************************************************
The times:1
Dataset: cora
Label_rate: 0.02
idx_train: [586, 1912, 1905, 707, 1540, 1374, 1713, 2055, 2402, 306, 1777, 329, 153, 2476, 1486, 871, 173, 1990, 1833, 689, 1114, 762, 1092, 2629, 756, 658, 546, 695, 1217, 1298, 2148, 1440, 784, 1413, 1611, 1944, 997, 2700, 1315, 498, 2289, 2260, 378, 583, 12, 2123, 1240, 443, 2527, 661, 755, 671, 119, 995, 1683, 2422, 1487, 447]
RNM flitering...
RNM fliter over.
The times:1 ||  Model_one_testacc:75.8081% ||  Model_two_testacc:77.3723% ||  Best_acc:80.1877% 
Test_acc:80.19%
*******************************************************************************************************

*******************************************************************************************************
The times:2
Dataset: cora
Label_rate: 0.02
idx_train: [2201, 738, 2136, 1395, 1922, 164, 2502, 2053, 589, 1834, 655, 958, 1699, 2389, 2614, 732, 1070, 1427, 263, 853, 650, 558, 332, 1573, 2632, 1893, 1294, 699, 1657, 2692, 1130, 877, 2206, 2699, 1423, 1465, 775, 254, 1497, 1449, 956, 698, 348, 2290, 2682, 2238, 2353, 1051, 1168, 1840, 1707, 940, 1899, 370, 1525, 2468, 1593, 26]
RNM flitering...
RNM fliter over.
The times:2 ||  Model_one_testacc:11.5746% ||  Model_two_testacc:11.5746% ||  Best_acc:81.7518% 
Test_acc:81.75%
*******************************************************************************************************

*******************************************************************************************************
The times:3
Dataset: cora
Label_rate: 0.02
idx_train: [591, 2578, 2295, 1395, 679, 2180, 2499, 2277, 505, 1335, 968, 2026, 1560, 1725, 1734, 156, 2447, 1689, 1714, 1756, 2514, 1648, 678, 2559, 2698, 1319, 1563, 841, 1823, 482, 316, 226, 2405, 674, 2108, 2000, 1814, 827, 2495, 1667, 1649, 442, 1519, 2237, 1266, 2248, 1481, 2337, 300, 1039, 410, 1441, 1700, 793, 1976, 1647, 2192, 1660]
RNM flitering...
RNM fliter over.
The times:3 ||  Model_one_testacc:12.8259% ||  Model_two_testacc:12.8259% ||  Best_acc:81.8561% 
Test_acc:81.86%
*******************************************************************************************************

*******************************************************************************************************
The times:4
Dataset: cora
Label_rate: 0.02
idx_train: [1909, 838, 292, 2267, 478, 2469, 1523, 1913, 1180, 2092, 318, 1705, 176, 480, 754, 1736, 72, 156, 758, 359, 2389, 464, 2091, 1863, 1053, 673, 2577, 1440, 2552, 2007, 2531, 2340, 1450, 841, 2692, 2301, 1996, 2633, 2128, 802, 271, 1143, 665, 1984, 714, 2378, 2226, 1569, 2058, 1060, 1226, 890, 2285, 1980, 2050, 663, 2030, 1165]
RNM flitering...
RNM fliter over.
The times:4 ||  Model_one_testacc:13.0344% ||  Model_two_testacc:13.0344% ||  Best_acc:81.9604% 
Test_acc:81.96%
*******************************************************************************************************

*******************************************************************************************************
The times:5
Dataset: cora
Label_rate: 0.02
idx_train: [65, 753, 861, 1536, 1279, 11, 496, 61, 460, 302, 406, 318, 139, 1895, 2523, 1070, 1210, 1832, 223, 687, 1734, 859, 1363, 1124, 2140, 633, 2152, 1062, 1440, 192, 1622, 1574, 1877, 899, 944, 664, 1992, 185, 382, 91, 2121, 2646, 2670, 378, 2684, 515, 805, 1907, 1885, 1500, 344, 1543, 2388, 807, 190, 93, 2467, 1849]
RNM flitering...
RNM fliter over.
The times:5 ||  Model_one_testacc:79.0407% ||  Model_two_testacc:79.1449% ||  Best_acc:82.3775% 
Test_acc:82.38%
*******************************************************************************************************

*******************************************************************************************************
The times:6
Dataset: cora
Label_rate: 0.02
idx_train: [2231, 1357, 2201, 437, 6, 1198, 2074, 2196, 1158, 968, 459, 1204, 460, 2522, 526, 355, 1990, 1281, 1155, 567, 1398, 1754, 1344, 1608, 1809, 2346, 841, 2477, 673, 2117, 1095, 1866, 923, 251, 1132, 2146, 421, 1270, 2539, 2563, 2341, 588, 2683, 2473, 1234, 1671, 1534, 1965, 2105, 2270, 1700, 1267, 2275, 516, 2158, 1593, 1399, 1163]
RNM flitering...
RNM fliter over.
The times:6 ||  Model_one_testacc:13.1387% ||  Model_two_testacc:13.1387% ||  Best_acc:81.0219% 
Test_acc:81.02%
*******************************************************************************************************

*******************************************************************************************************
The times:7
Dataset: cora
Label_rate: 0.02
idx_train: [1981, 61, 2181, 2089, 1927, 214, 1006, 257, 519, 2487, 1735, 1251, 1564, 1471, 2503, 1888, 931, 2372, 757, 2514, 1513, 919, 2493, 1692, 2243, 518, 669, 994, 1289, 1792, 1225, 291, 1026, 1221, 1151, 662, 532, 1503, 319, 91, 284, 2474, 1018, 320, 2435, 584, 2648, 2498, 1677, 1958, 2491, 1354, 1060, 2166, 1683, 1616, 898, 506]
RNM flitering...
RNM fliter over.
The times:7 ||  Model_one_testacc:79.7706% ||  Model_two_testacc:80.7091% ||  Best_acc:81.4390% 
Test_acc:81.44%
*******************************************************************************************************

*******************************************************************************************************
The times:8
Dataset: cora
Label_rate: 0.02
idx_train: [964, 2312, 2201, 2470, 1682, 2010, 1195, 531, 1552, 1780, 2318, 329, 829, 976, 1743, 105, 2439, 1990, 929, 1033, 635, 631, 2033, 708, 575, 2559, 1875, 521, 900, 1301, 416, 295, 599, 254, 1802, 692, 576, 1605, 986, 275, 787, 857, 1336, 1369, 2682, 780, 224, 2223, 1354, 1845, 1276, 1312, 220, 1828, 1170, 550, 850, 779]
RNM flitering...
RNM fliter over.
The times:8 ||  Model_one_testacc:13.2430% ||  Model_two_testacc:13.2430% ||  Best_acc:80.7091% 
Test_acc:80.71%
*******************************************************************************************************

*******************************************************************************************************
The times:9
Dataset: cora
Label_rate: 0.02
idx_train: [502, 323, 2499, 1526, 1078, 1517, 751, 305, 1009, 589, 505, 556, 2168, 1035, 635, 367, 322, 1722, 1378, 357, 1706, 1040, 2302, 1356, 790, 2149, 2410, 2118, 2242, 230, 2577, 2531, 1957, 1576, 178, 1212, 1159, 2245, 874, 665, 1569, 2547, 1518, 705, 63, 217, 1491, 2583, 2517, 472, 1880, 739, 1478, 973, 2638, 1675, 2396, 31]
RNM flitering...
RNM fliter over.
The times:9 ||  Model_one_testacc:12.0959% ||  Model_two_testacc:12.0959% ||  Best_acc:80.7091% 
Test_acc:80.71%
*******************************************************************************************************

*******************************************************************************************************
The times:10
Dataset: cora
Label_rate: 0.02
idx_train: [1083, 863, 1912, 1850, 2171, 214, 408, 861, 1768, 1767, 1009, 1786, 1772, 296, 2627, 797, 1471, 1617, 905, 1389, 2113, 565, 1091, 2541, 1937, 1855, 1106, 267, 1862, 639, 2152, 2634, 19, 2542, 1177, 2141, 746, 518, 2063, 2434, 583, 1261, 2306, 2323, 1401, 435, 1336, 1135, 644, 737, 163, 119, 1842, 1827, 2397, 1916, 414, 991]
RNM flitering...
RNM fliter over.
The times:10 ||  Model_one_testacc:76.5381% ||  Model_two_testacc:78.9364% ||  Best_acc:81.0219% 
Test_acc:81.02%
*******************************************************************************************************

*******************************************************************************************************
Dataset: cora
Label_rate: 0.02
Training set size: 58
Validation set size: 504
Test set size: 959
Random seed: 100
Use validation: False
Acc_all: [0.8018769551616267, 0.8175182481751825, 0.8185610010427529, 0.8196037539103233, 0.8237747653806048, 0.8102189781021898, 0.8143899895724713, 0.8070907194994786, 0.8070907194994786, 0.8102189781021898]
Acc_mean:81.30%
*******************************************************************************************************
